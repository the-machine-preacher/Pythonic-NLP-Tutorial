{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93283070",
   "metadata": {},
   "source": [
    "<img src=\"Images\\atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 1. Learning Objectives\n",
    "*Natural Language Processing*\n",
    "\n",
    "----\n",
    "- Understand what natural language processing is.\n",
    "- Identify several natural language processing techniques and how they relate to each other.\n",
    "- Try out a few natural language processing techniques using Python.\n",
    "- Implement basic regular expressions.\n",
    "- Recognize several techniques to prepare text for NLP tasks.\n",
    "- Use Python and regex to remove unnecessary formatting from your text.\n",
    "- Split text into tokens using NLTK.\n",
    "- Normalize text with Python, regex, and NLTK by removing affixes, changing case, and removing common words.\n",
    "- Work with regex patterns to find specific strings in your data.\n",
    "- Use NLTK to identify parts of speech.\n",
    "- Group words together by part-of-speech tags.\n",
    "- Remove specific chunks of text based on part-of-speech tags.\n",
    "- Identify common real-world applications for the bag-of-words (BoW) language model.\n",
    "- Convert text into a BoW representation using a Python dictionary.\n",
    "- Understand how feature dictionaries and feature vectors can be used to build a BoW model.\n",
    "- Recognize the difference between training data and test data.\n",
    "- Use scikit-learn to convert text into a BoW vector.\n",
    "- Identify advantages and disadvantages of BoW in relation to other common language models.\n",
    "- Understand how tf-idf helps you determine word importance within texts.\n",
    "- Implement tf-idf using scikit-learn.\n",
    "- Reframe word meaning based on context using word embeddings.\n",
    "- Understand how multi-dimensional vectors and distance metrics are useful for numerical representations of language.\n",
    "- Implement word embeddings, including word2vec, with spaCy and gensim.\n",
    "- Recognize why recurrent neural networks and specifically long short-term memory (LSTM) networks are helpful for working with sequences of text.\n",
    "- Convert text into a matrix of one-hot vectors.\n",
    "- Implement a seq2seq network using LSTM layers with teacher forcing.\n",
    "- Use deep learning to conduct machine translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0257a2ce",
   "metadata": {},
   "source": [
    "<img src=\"Images\\atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 2. Popular NLP Resources\n",
    "*Natural Language Processing*\n",
    "\n",
    "----\n",
    "As you go through the path, we’ll suggest certain resources for you to use, like articles, videos, tutorials, and documentation. Here are some additional resources that are considered groundbreaking, significant, or classics in the industry and will help you throughout your Path:\n",
    "- Documentation: [NLTK](https://www.nltk.org/)\n",
    "- Documentation: [re](https://docs.microsoft.com/en-us/dotnet/standard/base-types/regular-expression-language-quick-reference)\n",
    "- Documentation: [spaCy](https://spacy.io/usage)\n",
    "- Documentation: [gensim](https://radimrehurek.com/gensim/)\n",
    "- Documentation: [scikit-learn: Working with Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
    "- Documentation: [TensorFlow](https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt)\n",
    "\n",
    "<br/>Go ahead and bookmark these resources—you won’t need them now, but they’ll be useful to reference and use as you go through the Path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3b280",
   "metadata": {},
   "source": [
    "<img src=\"Images\\atom.png\" alt=\"Atom\" style=\"width:60px\" align=\"left\" vertical-align=\"middle\">\n",
    "\n",
    "## 3. Recommended Books\n",
    "*Natural Language Processing*\n",
    "\n",
    "----\n",
    "Sometimes it’s useful to have a couple of books on hand. The books featured in this Path are considered classics in the industry and many Codecademy learners (and employees!) have found them useful.\n",
    "- Book: [Algorithms of Oppression: How Search Engines Reinforce Racism, Safiya Umoja Noble](https://bookshop.org/books/algorithms-of-oppression-how-search-engines-reinforce-racism/9781479837243)\n",
    "- Book: [Speech and Language Processing (3rd ed. draft), Dan Jurafsky and James H. Martin](https://web.stanford.edu/~jurafsky/slp3/ed3book_dec302020.pdf)\n",
    "- Book: [Deep Learning with Python, François Chollet](https://bookshop.org/books/deep-learning-with-python/9781617294433)\n",
    "\n",
    "<br/>While the books listed are recommended and will help you on your NLP journey, purchasing and reading them is optional. When possible, we’ve suggested a free alternative. The content covers many of the same topics that you’ll find in our own lessons, but may be useful for those who want more explanation, a different perspective, or other opportunities for practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
